{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col,avg, when # pyspark sql functions\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DateType, TimestampType, DecimalType # pyspark sql types\n",
    "import random\n",
    "from faker import Faker\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    " \n",
    "\n",
    "# SPARK SETUP\n",
    "spark = SparkSession.builder.appName(\"Jupyter PySpark Example\").getOrCreate() # Create a SparkSession, which is the entry point to any Spark functionality\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Generate synthetic payment data, this would be the raw data, extract phase, ingestion phase.\n",
    "# can be replaced with data warehouse or data lake creation credentials which would means we skip the extract phase\n",
    "def generate_synthetic_data(num_records=1000):\n",
    "    data = []\n",
    "    for _ in range(num_records): \n",
    "        data.append({\n",
    "            'transaction_id': fake.uuid4(),\n",
    "            'customer_id': fake.uuid4(),\n",
    "            'customer_name': fake.name(),\n",
    "            'payment_amount': round(random.uniform(10.0, 1000.0), 2),\n",
    "            'payment_method': random.choice(['Credit Card', 'Debit Card', 'PayPal', 'Bank Transfer']),\n",
    "            'transaction_date': fake.date_this_year(),\n",
    "            'country': fake.country()\n",
    "        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1000 records of payment data\n",
    "payment_data = generate_synthetic_data(1000)\n",
    "\n",
    "# Convert to Pandas DataFrame before converting to spark dataframe,\n",
    "#  repartition the dataframe so that spark can handle it\n",
    "payment_df = pd.DataFrame(payment_data)\n",
    "# Convert to spark dataframe\n",
    "spark_payment_df = spark.createDataFrame(payment_df)\n",
    "\n",
    "# the dataframe is divided into 2 partitions, spark is a distributed system\n",
    "spark_payment_df = spark_payment_df.repartition(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- transaction_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- payment_amount: double (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      " |-- transaction_date: date (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n",
      "+-------+--------------------+--------------------+----------------+------------------+--------------+-----------+\n",
      "|summary|      transaction_id|         customer_id|   customer_name|    payment_amount|payment_method|    country|\n",
      "+-------+--------------------+--------------------+----------------+------------------+--------------+-----------+\n",
      "|  count|                1000|                1000|            1000|              1000|          1000|       1000|\n",
      "|   mean|                NULL|                NULL|            NULL|499.65305000000006|          NULL|       NULL|\n",
      "| stddev|                NULL|                NULL|            NULL|284.52596935083534|          NULL|       NULL|\n",
      "|    min|0016a1f9-f3d2-416...|004758b1-45cf-474...| Aaron Carpenter|             11.05| Bank Transfer|Afghanistan|\n",
      "|    max|ffe6a8d7-6234-458...|ffd83ab0-e83f-49a...|Zachary Buchanan|            999.79|        PayPal|   Zimbabwe|\n",
      "+-------+--------------------+--------------------+----------------+------------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the schema\n",
    "spark_payment_df.printSchema() # print the schema of the dataframe\n",
    "\n",
    "# Display the summary\n",
    "spark_payment_df.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[transaction_id: string, customer_id: string, customer_name: string, payment_amount: double, payment_method: string, transaction_date: date, country: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Row(transaction_id='ac3a043b-1f57-4577-970e-f85e747b26f0', customer_id='1d63e865-46a6-4b29-97cb-5e0cbcf01175', customer_name='Justin Rice', payment_amount=707.18, payment_method='Credit Card', transaction_date=datetime.date(2024, 5, 28), country='Italy'),\n",
       " Row(transaction_id='d3c75bd4-1bb2-4e53-8c08-56c36b1f20aa', customer_id='2f45f2be-94d4-4ef6-b78e-567b28902f26', customer_name='Denise Robles', payment_amount=348.13, payment_method='Debit Card', transaction_date=datetime.date(2024, 5, 24), country='Ireland'),\n",
       " Row(transaction_id='47a3ed21-5174-40a4-b216-6ee5ff691529', customer_id='c59be281-efd3-4c6e-98d8-8020e724c28c', customer_name='Christopher Santana', payment_amount=743.98, payment_method='Credit Card', transaction_date=datetime.date(2024, 6, 28), country='Burkina Faso'),\n",
       " Row(transaction_id='ad68da94-72a0-4a82-be89-3d0d058a8ccb', customer_id='b9c05b5c-e99e-4f01-bab6-73e6126bd4dc', customer_name='Jordan Bennett', payment_amount=455.01, payment_method='Debit Card', transaction_date=datetime.date(2024, 7, 19), country='Algeria'),\n",
       " Row(transaction_id='2b304bf7-a40a-44df-913d-250812bb107e', customer_id='004758b1-45cf-4747-bbc1-9a145e431fad', customer_name='Angela White', payment_amount=947.69, payment_method='Debit Card', transaction_date=datetime.date(2024, 4, 26), country='Angola'),\n",
       " Row(transaction_id='406aba1b-72f4-46d3-811b-9d8747c9c153', customer_id='28078295-0fc0-4ae8-9a2f-0a10c928c08a', customer_name='Matthew Grant', payment_amount=41.39, payment_method='Bank Transfer', transaction_date=datetime.date(2024, 9, 26), country='Poland'),\n",
       " Row(transaction_id='abd0f729-5784-4610-9f85-a1bd81b922a0', customer_id='ceb86824-c55f-41f1-8e35-2d45602270b3', customer_name='Clinton Hall', payment_amount=64.32, payment_method='Debit Card', transaction_date=datetime.date(2024, 3, 11), country='Myanmar'),\n",
       " Row(transaction_id='82c75a24-64d4-4150-b6da-d2df77816c9e', customer_id='c3712539-6291-4743-a5e9-2afa5c3bf2e7', customer_name='Kristopher Noble', payment_amount=517.11, payment_method='Credit Card', transaction_date=datetime.date(2024, 4, 7), country='Grenada'),\n",
       " Row(transaction_id='0a367147-2bdc-4551-8229-951b93eb0eb5', customer_id='70b3d4bb-ed1f-42d2-9c72-0ff3d9f540ae', customer_name='Richard Meyer', payment_amount=867.09, payment_method='PayPal', transaction_date=datetime.date(2024, 3, 5), country='Jamaica'),\n",
       " Row(transaction_id='e45e69ec-fd58-4a6e-92be-c6bc2b0fe1db', customer_id='dd87ecc6-fd70-44be-a203-d2830a128bf9', customer_name='Michelle Ward', payment_amount=76.61, payment_method='PayPal', transaction_date=datetime.date(2024, 5, 28), country='French Guiana')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first 10 records\n",
    "display(spark_payment_df.limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transaction_id', 'string'),\n",
       " ('customer_id', 'string'),\n",
       " ('customer_name', 'string'),\n",
       " ('payment_amount', 'double'),\n",
       " ('payment_method', 'string'),\n",
       " ('transaction_date', 'date'),\n",
       " ('country', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types\n",
    "spark_payment_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip time from the transaction_date, keeping only the date\n",
    "payment_df['transaction_date'] = pd.to_datetime(payment_df['transaction_date']).dt.normalize()\n",
    "\n",
    "# Convert the pandas DataFrame back to a Spark DataFrame\n",
    "spark_payment_df = spark.createDataFrame(payment_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[transaction_id: string, customer_id: string, customer_name: string, payment_amount: double, payment_method: string, transaction_date: timestamp, country: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[transaction_id: string, customer_id: string, customer_name: string, payment_amount: double, payment_method: string, transaction_date: timestamp, country: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark_payment_df.limit(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
